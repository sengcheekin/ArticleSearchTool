{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import pickle\n",
        "from langchain.chains import RetrievalQAWithSourcesChain\n",
        "from langchain.chains.qa_with_sources.loading import load_qa_with_sources_chain\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings import SentenceTransformerEmbeddings\n",
        "from langchain.document_loaders import UnstructuredURLLoader\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.llms import GPT4All\n",
        "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
        "from langchain.prompts import PromptTemplate\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "#load openAI api key\n",
        "os.environ['OPENAI_API_KEY'] = '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'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found model file at  D:\\\\Documents\\\\Interview Prep\\\\Code\\\\GPT4All\\\\orca-mini-3b.ggmlv3.q4_0.bin\n"
          ]
        }
      ],
      "source": [
        "callbacks=[StreamingStdOutCallbackHandler()]\n",
        "\n",
        "local_path = \"D:\\Documents\\Interview Prep\\Code\\GPT4All\\orca-mini-3b.ggmlv3.q4_0.bin\"\n",
        "\n",
        "llm = GPT4All(model=local_path, callbacks=callbacks, verbose=True)   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "prompt_template = \"\"\"Given the following extracted parts of a long document and a question, create a final answer with references (\"SOURCES\"). If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
        "{summaries}\n",
        "QUESTION: {question}\n",
        "SOURCES:\n",
        "FINAL ANSWER:\n",
        "\"\"\"\n",
        "doc_prompt_template = \"\"\"\n",
        "Content: {page_content}\n",
        "Source: {source}\n",
        "\"\"\"\n",
        "\n",
        "DOC_PROMPT = PromptTemplate(\n",
        "    template=doc_prompt_template, input_variables=[\"page_content\", \"source\"])\n",
        "\n",
        "PROMPT = PromptTemplate(\n",
        "    template=prompt_template, input_variables=[\"summaries\", \"question\"]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "r_splitter = RecursiveCharacterTextSplitter(\n",
        "    separators = [\"\\n\\n\", \"\\n\", \" \"],  # List of separators based on requirement (defaults to [\"\\n\\n\", \"\\n\", \" \"])\n",
        "    chunk_size = 1000,  # size of each chunk created\n",
        "    chunk_overlap  = 100,  # size of  overlap between chunks in order to maintain the context\n",
        "    length_function = len  # Function to calculate size, currently we are using \"len\" which denotes length of string however you can pass any token counter)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "loader = UnstructuredURLLoader(urls=[\n",
        "    \"https://finance.yahoo.com/news/nvidia-stock-falls-as-new-us-chip-rules-threaten-business-in-china-133336983.html\",\n",
        "    \"https://www.thestar.com.my/business/business-news/2023/10/20/asian-shares-plumb-11-mth-lows-on-surging-us-yields-middle-east-worries\",\n",
        "    \"https://www.theguardian.com/australia-news/2023/sep/05/mango-prices-higher-summer-warm-winter-queensland\"\n",
        "])\n",
        "data = loader.load()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "docs = r_splitter.split_documents(data)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "embeddings = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
        "# embeddings = OpenAIEmbeddings()\n",
        "\n",
        "vectorindex_openai = FAISS.from_documents(docs, embeddings)\n",
        "\n",
        "file_path = \"vector_index.pkl\"\n",
        "with open(file_path, \"wb\") as f:\n",
        "  pickle.dump(vectorindex_openai, f)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "file_path = \"vector_index.pkl\"\n",
        "\n",
        "if os.path.exists(file_path):\n",
        "    with open(file_path, \"rb\") as f:\n",
        "        vectorIndex = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "# qa_chain = load_qa_with_sources_chain(\n",
        "#     llm=llm,\n",
        "#     chain_type=\"stuff\",\n",
        "#     verbose=True,\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "RetrievalQAWithSourcesChain(verbose=True, combine_documents_chain=StuffDocumentsChain(llm_chain=LLMChain(prompt=PromptTemplate(input_variables=['summaries', 'question'], template='Given the following extracted parts of a long document and a question, create a final answer with references (\"SOURCES\"). If you don\\'t know the answer, just say that you don\\'t know, don\\'t try to make up an answer.\\n{summaries}\\nQUESTION: {question}\\nSOURCES:\\nFINAL ANSWER:\\n'), llm=GPT4All(verbose=True, callbacks=[<langchain.callbacks.streaming_stdout.StreamingStdOutCallbackHandler object at 0x000002B81D4BFC90>], model='D:\\\\Documents\\\\Interview Prep\\\\Code\\\\GPT4All\\\\orca-mini-3b.ggmlv3.q4_0.bin', client=<gpt4all.gpt4all.GPT4All object at 0x000002B81D53FE50>)), document_prompt=PromptTemplate(input_variables=['page_content', 'source'], template='\\nContent: {page_content}\\nSource: {source}\\n'), document_variable_name='summaries'), return_source_documents=True, retriever=VectorStoreRetriever(tags=['FAISS'], vectorstore=<langchain.vectorstores.faiss.FAISS object at 0x000002B823AD8FD0>))"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chain_type_kwargs = {\"prompt\": PROMPT, \"document_prompt\": DOC_PROMPT }\n",
        "chain = RetrievalQAWithSourcesChain.from_chain_type(llm=llm, chain_type=\"stuff\",retriever=vectorIndex.as_retriever(),chain_type_kwargs=chain_type_kwargs,return_source_documents=True,verbose=True)\n",
        "chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "# chain = RetrievalQAWithSourcesChain.from_llm(llm=llm, retriever=vectorIndex.as_retriever())\n",
        "# chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new RetrievalQAWithSourcesChain chain...\u001b[0m\n",
            "Asian shares plumbed 11-month lows on Friday as a relentless rise in long-term U.S. yields pressured valuations and investors shied away from risk due to mounting fears that Israel's war on Hamas could spark a wider Middle East conflict. Those fears also drove oil prices higher. Europe was set for a similarly downbeat open, with EUROSTOXX 50 futures sliding 0.6% and FTSE futures off 0.4%. S&P 500 futures were down 0.1%, while Nasdaq futures were down 0.3%.\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Asian shares plumbed 11-month lows on Friday as a relentless rise in long-term U.S. yields pressured valuations and investors shied away from risk due to mounting fears that Israel's war on Hamas could spark a wider Middle East conflict. Those fears also drove oil prices higher. Europe was set for a similarly downbeat open, with EUROSTOXX 50 futures sliding 0.6% and FTSE futures off 0.4%. S&P 500 futures were down 0.1%, while Nasdaq futures were down 0.3%.\n",
            "https://www.thestar.com.my/business/business-news/2023/10/20/asian-shares-plumb-11-mth-lows-on-surging-us-yields-middle-east-worries\n"
          ]
        }
      ],
      "source": [
        "query = \"How is europe and china doing?\"\n",
        "\n",
        "# langchain.debug=True\n",
        "\n",
        "answer = chain({\"question\": query}, return_only_outputs=True)\n",
        "print(answer[\"answer\"])\n",
        "print(answer[\"source_documents\"][0].metadata[\"source\"]) # workaround to get the source, as langchain.RetrievalQAWithSourcesChain does not return the source properly."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyOiZMlpNI2qs3gawolBQJYl",
      "include_colab_link": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
