{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import pickle\n",
        "from langchain.chains import RetrievalQAWithSourcesChain\n",
        "from langchain.chains.qa_with_sources.loading import load_qa_with_sources_chain\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings import SentenceTransformerEmbeddings\n",
        "from langchain.document_loaders import UnstructuredURLLoader\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.llms import GPT4All\n",
        "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
        "from langchain.prompts import PromptTemplate\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#load openAI api key\n",
        "os.environ['OPENAI_API_KEY'] = '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'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "callbacks=[StreamingStdOutCallbackHandler()]\n",
        "\n",
        "local_path = \"D:\\Documents\\Interview Prep\\Code\\GPT4All\\orca-mini-3b.ggmlv3.q4_0.bin\"\n",
        "\n",
        "llm = GPT4All(model=local_path, callbacks=callbacks, verbose=True)   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "prompt_template = \"\"\"Given the following extracted parts of a long document and a question, create a final answer with references (\"SOURCES\"). If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
        "{summaries}\n",
        "QUESTION: {question}\n",
        "SOURCES:\n",
        "FINAL ANSWER:\n",
        "\"\"\"\n",
        "doc_prompt_template = \"\"\"\n",
        "Content: {page_content}\n",
        "Source: {source}\n",
        "\"\"\"\n",
        "\n",
        "DOC_PROMPT = PromptTemplate(\n",
        "    template=doc_prompt_template, input_variables=[\"page_content\", \"source\"])\n",
        "\n",
        "PROMPT = PromptTemplate(\n",
        "    template=prompt_template, input_variables=[\"summaries\", \"question\"]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "r_splitter = RecursiveCharacterTextSplitter(\n",
        "    separators = [\"\\n\\n\", \"\\n\", \" \"],  # List of separators based on requirement (defaults to [\"\\n\\n\", \"\\n\", \" \"])\n",
        "    chunk_size = 1000,  # size of each chunk created\n",
        "    chunk_overlap  = 100,  # size of  overlap between chunks in order to maintain the context\n",
        "    length_function = len  # Function to calculate size, currently we are using \"len\" which denotes length of string however you can pass any token counter)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "loader = UnstructuredURLLoader(urls=[\n",
        "    \"https://finance.yahoo.com/news/nvidia-stock-falls-as-new-us-chip-rules-threaten-business-in-china-133336983.html\",\n",
        "    \"https://www.thestar.com.my/business/business-news/2023/10/20/asian-shares-plumb-11-mth-lows-on-surging-us-yields-middle-east-worries\",\n",
        "    \"https://www.theguardian.com/australia-news/2023/sep/05/mango-prices-higher-summer-warm-winter-queensland\"\n",
        "])\n",
        "data = loader.load()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "docs = r_splitter.split_documents(data)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "embeddings = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
        "# embeddings = OpenAIEmbeddings()\n",
        "\n",
        "vectorindex_openai = FAISS.from_documents(docs, embeddings)\n",
        "\n",
        "file_path = \"vector_index.pkl\"\n",
        "with open(file_path, \"wb\") as f:\n",
        "  pickle.dump(vectorindex_openai, f)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "file_path = \"vector_index.pkl\"\n",
        "\n",
        "if os.path.exists(file_path):\n",
        "    with open(file_path, \"rb\") as f:\n",
        "        vectorIndex = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# qa_chain = load_qa_with_sources_chain(\n",
        "#     llm=llm,\n",
        "#     chain_type=\"stuff\",\n",
        "#     verbose=True,\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "chain_type_kwargs = {\"prompt\": PROMPT, \"document_prompt\": DOC_PROMPT }\n",
        "chain = RetrievalQAWithSourcesChain.from_chain_type(llm=llm, chain_type=\"stuff\",retriever=vectorIndex.as_retriever(),chain_type_kwargs=chain_type_kwargs,return_source_documents=True,verbose=True)\n",
        "chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# chain = RetrievalQAWithSourcesChain.from_llm(llm=llm, retriever=vectorIndex.as_retriever())\n",
        "# chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "query = \"How is europe and china doing?\"\n",
        "\n",
        "# langchain.debug=True\n",
        "\n",
        "answer = chain({\"question\": query}, return_only_outputs=True)\n",
        "print(answer[\"answer\"])\n",
        "print(answer[\"source_documents\"][0].metadata[\"source\"]) # workaround to get the source, as langchain.RetrievalQAWithSourcesChain does not return the source properly."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyOiZMlpNI2qs3gawolBQJYl",
      "include_colab_link": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
